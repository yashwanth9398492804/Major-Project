{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSw4RiRO1ioX"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9KUOExb0lJr"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSQVfyCJ05Mc"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFHRqlom58TL"
   },
   "outputs": [],
   "source": [
    "SIZE = 64\n",
    "\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "for directory_path in glob.glob(r\"/content/drive/MyDrive/dataset/dataset_split/train/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        #print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "#print(train_images)\n",
    "train_images = np.array(train_images)\n",
    "print(train_images[0])\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74fKuj1xVfmZ"
   },
   "outputs": [],
   "source": [
    "print(train_labels[0])\n",
    "print(len(set(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQJ-lERbU9gR"
   },
   "outputs": [],
   "source": [
    "# test\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "for directory_path in glob.glob(r\"/content/drive/MyDrive/dataset/dataset_split/test/*\"):\n",
    "    fruit_label = directory_path.split(\"\\\\\")[-1]\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(fruit_label)\n",
    "        \n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdycIO79VsXT"
   },
   "outputs": [],
   "source": [
    "print(len(set(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1g22r9DMww_"
   },
   "outputs": [],
   "source": [
    "#Encode labels from text to integers.\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "print(train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "id9-EJk9UinA"
   },
   "outputs": [],
   "source": [
    "#Split data\n",
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2sIs2o2Ul_W"
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKlea6PEVXcZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D46Rt5vHUFOW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcegu492NU_U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGwEey2-Va-0"
   },
   "outputs": [],
   "source": [
    "#One hot encode y values for neural network. \n",
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAKlI8d4Uqol"
   },
   "source": [
    "Feature Extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Vl5IqW3U-df"
   },
   "outputs": [],
   "source": [
    "\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "VGG_model.summary()\n",
    "feature_extractor=VGG_model.predict(x_train)\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
    "print(len(VGG_model.layers))\n",
    "X_test=VGG_model.predict(x_test)\n",
    "X_for_RF = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztkcZaLzoEp6"
   },
   "outputs": [],
   "source": [
    "VGG_model.save('vgg16_feature_extractor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgK6LXEMo3Hs"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "def load_model(path):\n",
    "    model = keras.models.load_model(path)\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "path=r\"/content/vgg16_feature_extractor.h5\"\n",
    "model2=load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4MrTBgLpPk1"
   },
   "outputs": [],
   "source": [
    "model2.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixQAsvlNVz2b"
   },
   "outputs": [],
   "source": [
    "X_test=X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VdribwBVFJC"
   },
   "outputs": [],
   "source": [
    "print(X_for_RF.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arz9_ptAVTdg"
   },
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40cYguOmwmoL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnqUdW-Nwr7Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THHcOTi-wukT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3spY_Mtywx7I"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "pred_rf=rf.predict(val_features)\n",
    "print(metrics.accuracy_score(pred_rf,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvD9-zRMf3Kq"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(rf, 'rf_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "reFZN-Cvxe0Q"
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6rRX36Bxhla"
   },
   "outputs": [],
   "source": [
    "pred_svm=svm.predict(val_features)\n",
    "print(metrics.accuracy_score(pred_svm,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LY7mkrSqgtlU"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(svm,'svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mvO0sEORy_N"
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYRD22-JziHh"
   },
   "outputs": [],
   "source": [
    "pred_xgb = xgb.predict(val_features)\n",
    "print(metrics.accuracy_score(pred_xgb,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-zuJEi9g8og"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(xgb,'xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBbiDcPr1kd7"
   },
   "outputs": [],
   "source": [
    "train_predrf=rf.predict(train_features)\n",
    "train_predsvm=svm.predict(train_features)\n",
    "train_predxgb=xgb.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ehaj9jCW-gYM"
   },
   "outputs": [],
   "source": [
    "# Concatenate the base classifier predictions with the VGG16 features\n",
    "#base_preds = np.column_stack((pred_rf, pred_svm,pred_xgb))\n",
    "b_preds=np.column_stack((train_predrf,train_predsvm,train_predxgb))\n",
    "print(b_preds.shape)\n",
    "input_data = np.concatenate((train_features, b_preds), axis=1)\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMhmyVVKE21k"
   },
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "print(val_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SppNdEa1AHV7"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "timesteps=1\n",
    "input_dim=4096\n",
    "num_classes=10\n",
    "batch_size=32\n",
    "epochs=1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(1, input_data.shape[1])))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6gOv8GuAZ1H"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zqCzHP9AlRx"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(np.expand_dims(input_data, axis=1), y_train_one_hot, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JCXxNpYwSba"
   },
   "outputs": [],
   "source": [
    "X_test_stacked = np.column_stack((pred_rf, pred_svm, pred_xgb))\n",
    "xtest=np.concatenate((val_features, X_test_stacked), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_qaUdPdZUbD"
   },
   "outputs": [],
   "source": [
    "# Use the LSTM classifier to make predictions on the validation set\n",
    "lstm_preds = np.round(model.predict(xtest[:,np.newaxis,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZPgmMm3VQ53"
   },
   "outputs": [],
   "source": [
    "model.save(\"stackedLSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GK6s14qaWx2g"
   },
   "outputs": [],
   "source": [
    "# Evaluate the LSTM predictions\n",
    "accu = np.mean(ymodel1_preds == y_test_one_hot)\n",
    "print(f'LSTM accuracy: {accu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ML5mDaH_Mcog"
   },
   "source": [
    "Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrHrlhOyf1a_"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "clf4 = keras.models.load_model(r'/content/drive/MyDrive/dataset/LSTMmodel.h5')\n",
    "# Predict the class probabilities for each classifier\n",
    "y_proba4 = clf4.predict(np.expand_dims(val_features, axis=1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BgkkaFO0EXl"
   },
   "outputs": [],
   "source": [
    "# Combine the predictions of the base classifiers using majority voting\n",
    "majority_preds = np.array([np.argmax(np.bincount(preds.astype(int))) for preds in np.column_stack((pred_rf,pred_svm,pred_xgb))],dtype=int)\n",
    "\n",
    "# Evaluate the majority voting ensemble on the validation set\n",
    "accuracy = np.mean(majority_preds == val_labels)\n",
    "print('Majority Voting Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLcSgtLo7f-y"
   },
   "source": [
    "UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6oxreO7GUu07"
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import load_img, img_to_array \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import askopenfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A4I9qNeSV5EY"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "def load_model(path):\n",
    "    model = keras.models.load_model(path)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "path=r\"D:\\Dataset\\Models\\stackedLSTM.h5\"\n",
    "model1=load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uicQRl0uWNCm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "def load_model(path):\n",
    "    model = keras.models.load_model(path)\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "path=r\"D:\\Dataset\\Models\\vgg16_feature_extractor.h5\"\n",
    "model2=load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEYVY3oIxnvF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kC2bcvgHX_v6"
   },
   "outputs": [],
   "source": [
    "labels_dict= {0:'AnnualCrop', 1:'Forest', 2:'HerbaceousVegetation', 3:'Highway',\n",
    "       4:'Industrial', 5:'Pasture', 6:'PermanentCrop', 7:'Residential', 8:'River',\n",
    "       9:'SeaLake'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hpHwTDJHiOgk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator SVC from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:39:14] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "loaded_model1 = load(r'D:\\Dataset\\Models\\rf_model.pkl')\n",
    "loaded_model2=load(r'D:\\Dataset\\Models\\svm_model.pkl')\n",
    "loaded_model3=load(r'D:\\Dataset\\Models\\xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "QYOMAQQ_YuLk"
   },
   "outputs": [],
   "source": [
    "def predict(imagePath):\n",
    "    test_image = load_img(imagePath, target_size = (64,64)) \n",
    "    test_image = img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    img_feature_extractor=model2.predict(test_image)\n",
    "    img_feature=img_feature_extractor.reshape(img_feature_extractor.shape[0], -1)\n",
    "    feat1=loaded_model1.predict(img_feature)\n",
    "    feat2=loaded_model2.predict(img_feature)\n",
    "    feat3=loaded_model3.predict(img_feature)\n",
    "    test_image_stacked = np.column_stack((feat1,feat2,feat3))\n",
    "    test_image_feat=np.concatenate((img_feature,test_image_stacked), axis=1)\n",
    "    print(test_image_feat.shape)\n",
    "    result = model1.predict(test_image_feat[:,np.newaxis,:])\n",
    "    monocot=labels_dict[np.argmax(result)]\n",
    "    print(monocot)\n",
    "    l2 = tk.Label(my_w,text=\"This is \"+monocot,font=my_font1,bg=\"#ADEFD1\", fg=\"#00203F\")\n",
    "    imagepath=\"\"\n",
    "    l2.place(x=325,y=275)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "CoSHqTXZZAsM"
   },
   "outputs": [],
   "source": [
    "def upload_file():\n",
    "    f_types = [('Jpg Files', '*.jpg')]   # type of files to select\n",
    "    global filename\n",
    "    filename = tk.filedialog.askopenfilename(multiple=True,filetypes=f_types)\n",
    "\n",
    "    for f in filename:\n",
    "        img=PIL.Image.open(f) # read the image file\n",
    "        img=img.resize((64,64)) # new width & height\n",
    "        img=ImageTk.PhotoImage(img)\n",
    "        e1 =tk.Label(my_w)\n",
    "        e1.place(x=365,y=140)\n",
    "\n",
    "        e1.image = img\n",
    "        e1['image']=img\n",
    " # Keep the window open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "klfdDwSbZEe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "(1, 2051)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Highway\n"
     ]
    }
   ],
   "source": [
    "my_w = tk.Tk()\n",
    "my_w.geometry(\"800x350\")  # Size of the window\n",
    "my_w.configure(bg='#ADEFD1')\n",
    "my_w.title('Land classification')\n",
    "my_font1=('times', 14, 'bold')\n",
    "my_font2=('times',18,'bold')\n",
    "l1 = tk.Label(my_w,text='Upload Files & display',font=my_font1,bg=\"#ADEFD1\", fg=\"#00203F\")\n",
    "l2 = tk.Label(my_w,text='A Hybrid model built on VGG16 and LSTM for Land classification',font=my_font2,bg=\"#ADEFD1\", fg=\"#00203F\")\n",
    "l2.place(x=50,y=10)\n",
    "l1.place(x=300,y=70)\n",
    "b1 = tk.Button(my_w, text='Choose File',\n",
    "   width=20,command = lambda:upload_file(),bg=\"#00203F\", fg=\"#ADEFD1\")\n",
    "b1.place(x=325,y=100)\n",
    "b2 = tk.Button(my_w, text='Predict',\n",
    "       width=20,command = lambda:predict(filename[0]),bg=\"#00203F\", fg=\"#ADEFD1\")\n",
    "b2.place(x=325,y=230)\n",
    "my_w.mainloop() "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
